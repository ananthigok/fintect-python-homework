{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit 12 - Tales from the Crypto\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Sentiment Analysis\n",
    "\n",
    "Use the [newsapi](https://newsapi.org/) to pull the latest news articles for Bitcoin and Ethereum and create a DataFrame of sentiment scores for each coin.\n",
    "\n",
    "Use descriptive statistics to answer the following questions:\n",
    "1. Which coin had the highest mean positive score?\n",
    "2. Which coin had the highest negative score?\n",
    "3. Which coin had the highest positive score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/ananthigokul/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Initial imports\n",
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime, timedelta\n",
    "import nltk as nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from newsapi.newsapi_client import NewsApiClient\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "import string\n",
    "from collections import Counter\n",
    "from nltk import ngrams\n",
    "from nltk.corpus import stopwords, reuters\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b011deb799c1445e868b4c1defd6a8c1\n"
     ]
    }
   ],
   "source": [
    "# Read your api key environment variable\n",
    "# Load .env enviroment variables\n",
    "load_dotenv()\n",
    "\n",
    "news_api_key = os.getenv(\"NEWS_API_KEY\")\n",
    "print (news_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a newsapi client\n",
    "newsapi = NewsApiClient(api_key=news_api_key) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching news about 'Bitcoin'\n",
      "******************************\n",
      "retrieving news from: 2021-08-09 00:00:00\n",
      "retrieving news from: 2021-08-08 00:00:00\n",
      "retrieving news from: 2021-08-07 00:00:00\n",
      "([[], [\"Why a Waste-Coal Power Plant is 'Burning for Bitcoin'\", 'Blockchain could change the world. This $20 course package could show you how.', '$300 Billion Crypto Price Boom: Bitcoin Is Suddenly Soaring Toward $50,000 As Ethereum, BNB, Cardano, XRP, Dogecoin And Uniswap Surge', 'Crypto Price Prediction: Dogecoin ‘Pump And Dump’ Cycle Could Send The Memecoin Soaring By The End Of 2021', 'The Crypto Daily – Movers and Shakers – August 8th, 2021', 'Bitcoin Long-Term Buy Indicator Just Flashed as BTC Faces Critical Resistance (Price Analysis) - CryptoPotato', 'Bitcoin Trader’s Quietly Using In-cloud Apps for Steady Profits!', 'Stablecoins: Risks & regulatory imperatives', \"Why a Waste-Coal Power Plant is 'Burning for Bitcoin'\", 'What is ethereum’s London hard fork & how it will impact the crypto world? RT’s Boom Bust finds out', 'Bitcoin hits $45K ahead of July inflation report, but one fractal hints at looming correction', 'DOGE and SHIB See Biggest Gains in Top 100 Over Weekend', \"Bitcoin can't be viewed as an untraceable 'crime coin' anymore\", 'Is the Cryptocurrency Bear Market Over?', 'What is etherium’s London hard fork & how it will impact the crypto world? RT’s Boom Bust finds out', 'The biggest challenge for crypto exchanges is global price fragmentation', 'U.S. Senators Forge Crypto Tax Reporting Rules Over The Weekend', 'Coinbase now offers instant cash withdrawals of up to $100,000', 'What Investors Need To Know When Disney And Coinbase Report Earnings This Week', 'Bitcoin Tests Resistance Near $45,000 After Breaking Free Of Prior Range'], [\"Why a Waste-Coal Power Plant is 'Burning for Bitcoin'\", 'Blockchain could change the world. This $20 course package could show you how.', '5 Websites to Track Live Bitcoin Exchange Rates', '$300 Billion Crypto Price Boom: Bitcoin Is Suddenly Soaring Toward $50,000 As Ethereum, BNB, Cardano, XRP, Dogecoin And Uniswap Surge', '10 Weekend Reads', 'Bitcoin and Ether hit highest since mid-May as sentiment warms', 'Crypto Price Prediction: Dogecoin ‘Pump And Dump’ Cycle Could Send The Memecoin Soaring By The End Of 2021', 'The Bitcoin Honey Badger Voting Bloc', 'The Crypto Daily – Movers and Shakers – August 8th, 2021', 'Now Zuckerberg wants Facebook to be master of the virtual universe | Alex Hern', 'Bitcoin Long-Term Buy Indicator Just Flashed as BTC Faces Critical Resistance (Price Analysis) - CryptoPotato', 'Bitcoin Trader’s Quietly Using In-cloud Apps for Steady Profits!', 'Stablecoins: Risks & regulatory imperatives', 'RBI may come out with model on India’s digital currency by year-end', 'The Crypto Daily – Movers and Shakers – August 7th, 2021', \"Why a Waste-Coal Power Plant is 'Burning for Bitcoin'\", 'What is ethereum’s London hard fork & how it will impact the crypto world? RT’s Boom Bust finds out', 'Bitcoin and Ether hit highest since mid-May as sentiment warms - Mint', 'Ethereum Crosses $3,100 With 14% Rally: At Its Highest Since May', 'Bitcoin SV rocked by three 51% attacks in as many months']], [datetime.datetime(2021, 8, 9, 0, 0), datetime.datetime(2021, 8, 8, 0, 0), datetime.datetime(2021, 8, 7, 0, 0)])\n"
     ]
    }
   ],
   "source": [
    "# Fetch the Bitcoin news articles\n",
    "\n",
    "# Set current date and the date from one month ago using the ISO format\n",
    "current_date = pd.Timestamp(datetime.now(), tz=\"America/New_York\").isoformat()\n",
    "past_date = pd.Timestamp(datetime.now()- timedelta(3), tz=\"America/New_York\").isoformat()\n",
    "\n",
    "# Use newsapi client to get most relevant 20 headlines per day in the past month\n",
    "def get_news_articles(keyword):\n",
    "    all_headlines = []\n",
    "    all_dates = []    \n",
    "    date = datetime.strptime(current_date[:10], \"%Y-%m-%d\")\n",
    "    end_date = datetime.strptime(past_date[:10], \"%Y-%m-%d\")\n",
    "    print(f\"Fetching news about '{keyword}'\")\n",
    "    print(\"*\" * 30)\n",
    "    while date > end_date:\n",
    "        print(f\"retrieving news from: {date}\")\n",
    "        articles = newsapi.get_everything(\n",
    "            q=keyword,\n",
    "            from_param=str(date)[:10],\n",
    "            #to=str(date)[:10],\n",
    "            language=\"en\",\n",
    "            sort_by=\"relevancy\",\n",
    "            page=1,\n",
    "        )\n",
    "        headlines = []\n",
    "        for i in range(0, len(articles[\"articles\"])):\n",
    "            headlines.append(articles[\"articles\"][i][\"title\"])\n",
    "        all_headlines.append(headlines)\n",
    "        all_dates.append(date)\n",
    "        date = date - timedelta(days=1)\n",
    "    return all_headlines, all_dates\n",
    "\n",
    "news = get_news_articles('Bitcoin')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-6478f2a72ea2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnews\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "news.head()\n",
    "## df with news - TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blockchain infrastructure startups are heating up as industry fervor brings more developers and users to a space that still feels extremely young despite a heavy institutional embrace of the crypto space in 2021. The latest crypto startup to court the attenti…\n",
      "Blockchain infrastructure startups are heating up as industry fervor brings more developers and users to a space that still feels extremely young despite a heavy institutional embrace of the crypto space in 2021. The latest crypto startup to court the attenti…\n"
     ]
    }
   ],
   "source": [
    "# Fetch the Ethereum news articles\n",
    "#get_news_articles('Ethereum')\n",
    "ethereum_headlines = newsapi.get_everything(q=\"Ethereum\", language=\"en\")\n",
    "#print(ethereum_headlines)\n",
    "print(ethereum_headlines['articles'][1]['description'])\n",
    "\n",
    "bitcoin_headlines = newsapi.get_everything(q=\"Bitcoin\", language=\"en\")\n",
    "#print(ethereum_headlines)\n",
    "print(ethereum_headlines['articles'][1]['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    When my wife started a little garden in our ur...\n",
      "Name: content, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Create the Bitcoin sentiment scores DataFrame\n",
    "def headline_sentiment_summarizer_avg(headlines):\n",
    "    sentiment = []\n",
    "    for day in headlines:\n",
    "        day_score = []\n",
    "        for h in day:\n",
    "            if h == None:\n",
    "                continue\n",
    "            else:\n",
    "                day_score.append(sid.polarity_scores(h)[\"compound\"])\n",
    "        sentiment.append(sum(day_score) / len(day_score))\n",
    "    return sentiment\n",
    "#bitcoin_headlines = newsapi.get_top_headlines(q=\"bitcoin\", language=\"en\", country=\"ca\")\n",
    "bitcoin_headlines = newsapi.get_everything(q=\"Bitcoin\", language=\"en\")\n",
    "#print(bitcoin_headlines)\n",
    "bitcoin_df = pd.DataFrame.from_dict(bitcoin_headlines[\"articles\"])\n",
    "\n",
    "\n",
    "bitcoin_df_first = bitcoin_df.head(1) ## bitcoin_df.iloc(:1)\n",
    "print (bitcoin_df_first['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    When my wife started a little garden in our ur...\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Ethereum sentiment scores DataFrame\n",
    "# YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the Bitcoin Sentiment\n",
    "# YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the Ethereum Sentiment\n",
    "# YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "\n",
    "Q: Which coin had the highest mean positive score?\n",
    "\n",
    "A: \n",
    "\n",
    "Q: Which coin had the highest compound score?\n",
    "\n",
    "A: \n",
    "\n",
    "Q. Which coin had the highest positive score?\n",
    "\n",
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Natural Language Processing\n",
    "---\n",
    "###   Tokenizer\n",
    "\n",
    "In this section, you will use NLTK and Python to tokenize the text for each coin. Be sure to:\n",
    "1. Lowercase each word.\n",
    "2. Remove Punctuation.\n",
    "3. Remove Stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from string import punctuation\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Create a list of stopwords\n",
    "stop_words = set(stopwords.words('english')) \n",
    "print (len(stop_words))\n",
    "\n",
    "# Expand the default stopwords list if necessary\n",
    "# YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete the tokenizer function\n",
    "def tokenizer(text):\n",
    "    \"\"\"Tokenizes text.\"\"\"\n",
    "    \n",
    "    # Remove the punctuation from text\n",
    "    regex = re.compile(\"[^a-zA-Z ]\")\n",
    "    re_clean = regex.sub('', text)\n",
    "    #text.astype()\n",
    "    text.translate(str.maketrans('', '', string.punctuation))#.translate(None, string.punctuation)\n",
    "    \n",
    "    # Create a tokenized list of the words\n",
    "    word_tokens = word_tokenize(re_clean)\n",
    "\n",
    "    # Lemmatize words into root words\n",
    "    lem = [lemmatizer.lemmatize(word) for word in word_tokens]\n",
    "   \n",
    "    # Convert the words to lowercase\n",
    "    output = [word.lower() for word in lem if word.lower() not in stop_words]\n",
    "    \n",
    "    # Remove the stop words\n",
    "    filtered_sentence = [] \n",
    "    for w in word_tokens: \n",
    "        if w not in stop_words: \n",
    "            filtered_sentence.append(w) \n",
    "\n",
    "    print(\"\\n\\nOriginal Sentence \\n\\n\")\n",
    "    print(\" \".join(word_tokens)) \n",
    "\n",
    "    print(\"\\n\\nFiltered Sentence \\n\\n\")\n",
    "    print(\" \".join(filtered_sentence)) \n",
    "    ## TODO check with tutor \n",
    "    tokens = filtered_sentence\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    When my wife started a little garden in our ur...\n",
      "Name: content, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Create a new tokens column for Bitcoin\n",
    "text_df = bitcoin_df_first['content'].to_frame()\n",
    "text_bitcoin = text_df['content'].astype(str)\n",
    "print (text_bitcoin)\n",
    "#tokens = tokenizer(text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blockchain infrastructure startups are heating up as industry fervor brings more developers and users to a space that still feels extremely young despite a heavy institutional embrace of the crypto space in 2021. The latest crypto startup to court the attenti…\n",
      "\n",
      "\n",
      "Original Sentence \n",
      "\n",
      "\n",
      "Blockchain infrastructure startups are heating up as industry fervor brings more developers and users to a space that still feels extremely young despite a heavy institutional embrace of the crypto space in The latest crypto startup to court the attenti\n",
      "\n",
      "\n",
      "Filtered Sentence \n",
      "\n",
      "\n",
      "Blockchain infrastructure startups heating industry fervor brings developers users space still feels extremely young despite heavy institutional embrace crypto space The latest crypto startup court attenti\n"
     ]
    }
   ],
   "source": [
    "# Create a new tokens column for Ethereum\n",
    "text_ethereum = ethereum_headlines['articles'][1]['description']\n",
    "print (text_ethereum)\n",
    "tokens = tokenizer(text_ethereum) \n",
    "#print (news[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NGrams and Frequency Analysis\n",
    "\n",
    "In this section you will look at the ngrams and word frequency for each coin. \n",
    "\n",
    "1. Use NLTK to produce the n-grams for N = 2. \n",
    "2. List the top 10 words for each coin. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(doc):\n",
    "    sw = set(stopwords.words('english'))\n",
    "    regex = re.compile(\"[^a-zA-Z ]\")\n",
    "    re_clean = regex.sub('', doc)\n",
    "    words = word_tokenize(re_clean)\n",
    "    lem = [lemmatizer.lemmatize(word) for word in words]\n",
    "    output = [word.lower() for word in lem if word.lower() not in sw]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['blockchain', 'infrastructure', 'startup', 'heating', 'industry', 'fervor', 'brings', 'developer', 'user', 'space', 'still', 'feel', 'extremely', 'young', 'despite', 'heavy', 'institutional', 'embrace', 'crypto', 'space', 'latest', 'crypto', 'startup', 'court', 'attenti']\n",
      "{('blockchain', 'infrastructure'): 1, ('infrastructure', 'startup'): 1, ('startup', 'heating'): 1, ('heating', 'industry'): 1, ('industry', 'fervor'): 1, ('fervor', 'brings'): 1, ('brings', 'developer'): 1, ('developer', 'user'): 1, ('user', 'space'): 1, ('space', 'still'): 1, ('still', 'feel'): 1, ('feel', 'extremely'): 1, ('extremely', 'young'): 1, ('young', 'despite'): 1, ('despite', 'heavy'): 1, ('heavy', 'institutional'): 1, ('institutional', 'embrace'): 1, ('embrace', 'crypto'): 1, ('crypto', 'space'): 1, ('space', 'latest'): 1, ('latest', 'crypto'): 1, ('crypto', 'startup'): 1, ('startup', 'court'): 1, ('court', 'attenti'): 1}\n"
     ]
    }
   ],
   "source": [
    "# Generate the Bitcoin N-grams where N=2\n",
    "#\n",
    "processed_text_bitcoin = process_text(text_bitcoin)#text_bitcoin)\n",
    "print(processed_text_bitcoin)\n",
    "\n",
    "bigram_counts_bitcoin = Counter(ngrams(processed_text_bitcoin, n=2))\n",
    "print(dict(bigram_counts_bitcoin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['blockchain', 'infrastructure', 'startup', 'heating', 'industry', 'fervor', 'brings', 'developer', 'user', 'space', 'still', 'feel', 'extremely', 'young', 'despite', 'heavy', 'institutional', 'embrace', 'crypto', 'space', 'latest', 'crypto', 'startup', 'court', 'attenti']\n",
      "{('blockchain', 'infrastructure'): 1, ('infrastructure', 'startup'): 1, ('startup', 'heating'): 1, ('heating', 'industry'): 1, ('industry', 'fervor'): 1, ('fervor', 'brings'): 1, ('brings', 'developer'): 1, ('developer', 'user'): 1, ('user', 'space'): 1, ('space', 'still'): 1, ('still', 'feel'): 1, ('feel', 'extremely'): 1, ('extremely', 'young'): 1, ('young', 'despite'): 1, ('despite', 'heavy'): 1, ('heavy', 'institutional'): 1, ('institutional', 'embrace'): 1, ('embrace', 'crypto'): 1, ('crypto', 'space'): 1, ('space', 'latest'): 1, ('latest', 'crypto'): 1, ('crypto', 'startup'): 1, ('startup', 'court'): 1, ('court', 'attenti'): 1}\n"
     ]
    }
   ],
   "source": [
    "# Generate the Ethereum N-grams where N=2\n",
    "processed_text_ethereum = process_text(text_ethereum)#text_bitcoin)\n",
    "print(processed_text_ethereum)\n",
    "\n",
    "bigram_counts = Counter(ngrams(processed_text_ethereum, n=2))\n",
    "print(dict(bigram_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function token_count generates the top 10 words for a given coin\n",
    "def token_count(tokens, N=3):\n",
    "    \"\"\"Returns the top N tokens from the frequency count\"\"\"\n",
    "    return Counter(tokens).most_common(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use token_count to get the top 10 words for Bitcoin\n",
    "# YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('blockchain', 'infrastructure'): 1, ('infrastructure', 'startup'): 1, ('startup', 'heating'): 1, ('heating', 'industry'): 1, ('industry', 'fervor'): 1, ('fervor', 'brings'): 1, ('brings', 'developer'): 1, ('developer', 'user'): 1, ('user', 'space'): 1, ('space', 'still'): 1}\n"
     ]
    }
   ],
   "source": [
    "# Use token_count to get the top 10 words for Ethereum\n",
    "print(dict(bigram_counts.most_common(10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Clouds\n",
    "\n",
    "In this section, you will generate word clouds for each coin to summarize the news for each coin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = [20.0, 10.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the Bitcoin word cloud\n",
    "# YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Category Ethereum not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-866f9ff6ae41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Generate the Ethereum word cloud\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mreuters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mreuters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Ethereum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreuters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Ethereum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/nltk/corpus/reader/api.py\u001b[0m in \u001b[0;36mfileids\u001b[0;34m(self, categories)\u001b[0m\n\u001b[1;32m    366\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c2f\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Category %s not found\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcategories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_f2c\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Category Ethereum not found"
     ]
    }
   ],
   "source": [
    "# Generate the Ethereum word cloud\n",
    "#https://monash.bootcampcontent.com/monash-coding-bootcamp/monu-mel-virt-fin-pt-05-2021-u-c/-/blob/master/Activities/Week%2012/2/07-Ins_Tone_Analysis/Solved/tone_analysis.ipynb\n",
    "from nltk.corpus import reuters\n",
    "print (reuters.fileids('Ethereum')) ## TODO \n",
    "\n",
    "ids = reuters.fileids(categories='Ethereum') ## TODO\n",
    "\n",
    "\n",
    "corpus = [reuters.raw(i) for i in ids]\n",
    "\n",
    "big_string = ' '.join(corpus)\n",
    "input_text = process_text(big_string)\n",
    "\n",
    "print (processed)\n",
    "\n",
    "wc = WordCloud().generate(input_text)\n",
    "plt.imshow(wc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Named Entity Recognition\n",
    "\n",
    "In this section, you will build a named entity recognition model for both Bitcoin and Ethereum, then visualize the tags using SpaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the language model for SpaCy\n",
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the spaCy model\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Bitcoin NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all of the Bitcoin text together\n",
    " # Set article to be analyzed with spaCy\n",
    "doc = nlp(text_ethereum) ## TODO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Blockchain infrastructure startups are heating up as industry fervor brings more developers and users to a space that still feels extremely young despite a heavy institutional embrace of the crypto space in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2021\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ". The latest crypto startup to court the attenti…</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run the NER processor on all of the text\n",
    "displacy.render(doc, style='ent')\n",
    "\n",
    "# Add a title to the document\n",
    "# YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render the visualization\n",
    "# YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# List all Entities\n",
    "print([ent.text for ent in doc.ents if ent.label_ == 'GPE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ethereum NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all of the Ethereum text together\n",
    "# YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the NER processor on all of the text\n",
    "# YOUR CODE HERE!\n",
    "\n",
    "# Add a title to the document\n",
    "# YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render the visualization\n",
    "# YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all Entities\n",
    "# YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python [conda env:root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
